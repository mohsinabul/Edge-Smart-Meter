{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyM4a7vdW2EKLseX9IzaVRYx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkmhQLus10mw","executionInfo":{"status":"ok","timestamp":1754930783362,"user_tz":-60,"elapsed":9030,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"00a701de-ab29-4414-d334-dfb53c46da88"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip -q install -U keras-tuner gputil"]},{"cell_type":"code","source":["import os, json, time, platform\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import keras_tuner as kt\n","import GPUtil\n","from google.colab import drive\n","from keras import ops as K"],"metadata":{"id":"cjsjAzetNgKv","executionInfo":{"status":"ok","timestamp":1754933889235,"user_tz":-60,"elapsed":19,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Colab: mount Drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKo8sNZM5cxB","executionInfo":{"status":"ok","timestamp":1754930817105,"user_tz":-60,"elapsed":33739,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"79b5a978-da74-48f3-ad0c-62ec6d910def"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Paths\n","DATA_DIR = \"/content/drive/MyDrive/EdgeMeter_AIv2/data\"\n","WIN_KEY  = \"48to12\"\n","WIN_TAG  = \"48_12\"\n","\n","HP_PATH  = os.path.join(DATA_DIR, f\"best_liteformer_hp_{WIN_KEY}.json\")\n","LOG_PATH = os.path.join(DATA_DIR, f\"liteformer_tuning_log_{WIN_KEY}.json\")\n","\n","# Reproducibility\n","tf.random.set_seed(42)\n","np.random.seed(42)"],"metadata":{"id":"Dmyn8s9u54qh","executionInfo":{"status":"ok","timestamp":1754930817109,"user_tz":-60,"elapsed":2,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# GPU info\n","gpus = tf.config.list_physical_devices('GPU')\n","print(\"GPUs visible to TF:\", gpus)\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","    except Exception:\n","        pass\n","gpu_name = GPUtil.getGPUs()[0].name if GPUtil.getGPUs() else \"None\"\n","print(\"GPU in use:\", gpu_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U0dL5aO65xvf","executionInfo":{"status":"ok","timestamp":1754930817986,"user_tz":-60,"elapsed":50,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"9cfa26fa-1969-4dc6-af9c-52cb4f761c9b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPUs visible to TF: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","GPU in use: NVIDIA A100-SXM4-40GB\n"]}]},{"cell_type":"code","source":["# Loading Data (48-12)\n","def _path(d, base, tag):\n","    p1 = os.path.join(d, f\"{base}_{tag}.npy\")\n","    p0 = os.path.join(d, f\"{base}.npy\")\n","    if os.path.exists(p1): return p1\n","    if os.path.exists(p0): return p0\n","    raise FileNotFoundError(f\"Missing {base}_{tag}.npy (or {base}.npy) in {d}\")\n","\n","X_train = np.load(_path(DATA_DIR, \"X_train\", WIN_TAG))\n","y_train = np.load(_path(DATA_DIR, \"y_train\", WIN_TAG))\n","X_val   = np.load(_path(DATA_DIR, \"X_val\",   WIN_TAG))\n","y_val   = np.load(_path(DATA_DIR, \"y_val\",   WIN_TAG))\n","X_test  = np.load(_path(DATA_DIR, \"X_test\",  WIN_TAG))\n","y_test  = np.load(_path(DATA_DIR, \"y_test\",  WIN_TAG))"],"metadata":{"id":"Bz77gn0a5013","executionInfo":{"status":"ok","timestamp":1754931145076,"user_tz":-60,"elapsed":327089,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Shape + NaN checks\n","assert X_train.ndim==3 and X_val.ndim==3 and X_test.ndim==3, \"X must be (N,T,F)\"\n","assert y_train.ndim==2 and y_val.ndim==2 and y_test.ndim==2, \"y must be (N,12)\"\n","assert y_train.shape[1]==12 and y_val.shape[1]==12 and y_test.shape[1]==12, \"y must have 12 steps\"\n","assert X_train.shape[1]==48, f\"Expected T=48; got {X_train.shape[1]}\"\n","for name, arr in [(\"X_train\",X_train),(\"X_val\",X_val),(\"X_test\",X_test),\n","                  (\"y_train\",y_train),(\"y_val\",y_val),(\"y_test\",y_test)]:\n","    if np.isnan(arr).any():\n","        raise ValueError(f\"NaNs detected in {name}\")\n","\n","timesteps  = X_train.shape[1]  # 48\n","n_features = X_train.shape[2]\n","out_steps  = y_train.shape[1]  # 12\n","\n","print(f\"Train X: {X_train.shape} | y: {y_train.shape}\")\n","print(f\"Val   X: {X_val.shape}   | y: {y_val.shape}\")\n","print(f\"Test  X: {X_test.shape}  | y: {y_test.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoYYvKjU59L6","executionInfo":{"status":"ok","timestamp":1754931150669,"user_tz":-60,"elapsed":5583,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"4b39f2c9-3759-488c-db51-77618a2aec10"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Train X: (10719826, 48, 11) | y: (10719826, 12)\n","Val   X: (3072784, 48, 11)   | y: (3072784, 12)\n","Test  X: (1536392, 48, 11)  | y: (1536392, 12)\n"]}]},{"cell_type":"code","source":["# 5% subset for fast tuning\n","subset_frac   = 0.05\n","n_train_small = max(1, int(subset_frac * X_train.shape[0]))\n","n_val_small   = max(1, int(subset_frac * X_val.shape[0]))\n","\n","X_train_small = X_train[:n_train_small]\n","y_train_small = y_train[:n_train_small]\n","X_val_small   = X_val[:n_val_small]\n","y_val_small   = y_val[:n_val_small]\n","\n","print(f\"Subset shapes → X_train_small: {X_train_small.shape} | X_val_small: {X_val_small.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5F_4cOiJ6ADO","executionInfo":{"status":"ok","timestamp":1754931150696,"user_tz":-60,"elapsed":7,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"384f85a2-1a61-453d-bbd8-24aa61377297"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Subset shapes → X_train_small: (535991, 48, 11) | X_val_small: (153639, 48, 11)\n"]}]},{"cell_type":"code","source":["# LiteFormer\n","def slice_patches(x, patch_size):\n","    # (B,T,F) → (B,P,patch_size*F), P = floor(T/patch_size)\n","    T = tf.shape(x)[1]\n","    F = tf.shape(x)[2]\n","    t_trim = (T // patch_size) * patch_size\n","    x = x[:, :t_trim, :]\n","    P = t_trim // patch_size\n","    return tf.reshape(x, [tf.shape(x)[0], P, patch_size * F])\n","\n","def build_liteformer_v1(hp):\n","    \"\"\"\n","    EXACT v1 LiteFormer block (do not change):\n","      - slice patches\n","      - Dense(hidden_dim)\n","      - + learnable positional embedding\n","      - Dense(hidden_dim, gelu) + Dropout\n","      - Linear attention via QKV (softmax(QK^T/sqrt(d))V) + Dropout\n","      - Residual + LayerNorm\n","      - FFN: Dense(2*hidden_dim, gelu) -> Dense(hidden_dim) + LayerNorm\n","      - GAP -> Dense(12)\n","    \"\"\"\n","    patch_size    = hp.Choice('patch_size', [4, 6, 8, 12])\n","    hidden_dim    = hp.Int('hidden_dim', 32, 128, step=16)\n","    dropout       = hp.Float('dropout', 0.0, 0.3, step=0.05)\n","    learning_rate = hp.Float('learning_rate', 1e-4, 5e-3, sampling='log')\n","\n","    inputs = keras.Input(shape=(timesteps, n_features))\n","    x = layers.Lambda(lambda t: slice_patches(t, patch_size))(inputs)   # (B,P,patch*F)\n","\n","    # Project to hidden_dim\n","    x = layers.Dense(hidden_dim)(x)\n","\n","    # Positional embedding (learnable)\n","    num_patches = timesteps // patch_size\n","    pos_embed = layers.Embedding(input_dim=num_patches, output_dim=hidden_dim)\n","    positions = tf.range(start=0, limit=num_patches, delta=1)\n","    pos_encoding = pos_embed(positions)         # (P, hidden_dim)\n","    x = x + pos_encoding                        # broadcast over batch\n","\n","    # Pre-attn transform\n","    x = layers.Dense(hidden_dim, activation='gelu')(x)\n","    x = layers.Dropout(dropout)(x)\n","\n","    # Linear attention (QKV)\n","    q = layers.Dense(hidden_dim)(x)\n","    k = layers.Dense(hidden_dim)(x)\n","    v = layers.Dense(hidden_dim)(x)\n","    scale = K.sqrt(K.cast(hidden_dim, \"float32\"))\n","\n","    attn_scores  = K.matmul(q, K.swapaxes(k, -1, -2)) / scale\n","    attn_weights = K.softmax(attn_scores, axis=-1)\n","    attn_output  = K.matmul(attn_weights, v)\n","\n","    # Residual + Norm\n","    x = layers.Add()([x, attn_output])\n","    x = layers.LayerNormalization(epsilon=1e-6)(x)\n","\n","    # FFN + Norm\n","    x = layers.Dense(hidden_dim * 2, activation='gelu')(x)\n","    x = layers.Dense(hidden_dim)(x)\n","    x = layers.LayerNormalization(epsilon=1e-6)(x)\n","\n","    # Head\n","    x = layers.GlobalAveragePooling1D()(x)\n","    outputs = layers.Dense(out_steps)(x)\n","\n","    model = keras.Model(inputs, outputs)\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n","        loss='mse',\n","        metrics=['mae']\n","    )\n","    return model"],"metadata":{"id":"GX1AJ9IG6EEL","executionInfo":{"status":"ok","timestamp":1754933892613,"user_tz":-60,"elapsed":16,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Tuner (BayesianOptimization)\n","tuner = kt.BayesianOptimization(\n","    build_liteformer_v1,\n","    objective=\"val_loss\",\n","    max_trials=20,\n","    directory=DATA_DIR,\n","    project_name=f\"liteformer_retune_{WIN_KEY}\"\n",")\n","\n","early_stop = keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\", patience=4, restore_best_weights=True\n",")\n","\n","device = \"/GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"\n","print(\"Using device:\", device)\n","\n","start_time = time.time()\n","with tf.device(device):\n","    tuner.search(\n","        X_train_small, y_train_small,\n","        validation_data=(X_val_small, y_val_small),\n","        epochs=50,\n","        batch_size=512,\n","        callbacks=[early_stop],\n","        verbose=1\n","    )\n","end_time = time.time()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPNvZMn_6I1y","executionInfo":{"status":"ok","timestamp":1754937242458,"user_tz":-60,"elapsed":3347544,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"a14aefb4-2a39-478b-ad3e-10719f019052"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 20 Complete [00h 02m 40s]\n","val_loss: 0.08746278285980225\n","\n","Best val_loss So Far: 0.08746278285980225\n","Total elapsed time: 00h 55m 47s\n"]}]},{"cell_type":"code","source":["# Saving best HPs\n","best_hp = tuner.get_best_hyperparameters(1)[0]\n","hp_dict = {\n","    \"patch_size\":    best_hp.get(\"patch_size\"),\n","    \"hidden_dim\":    best_hp.get(\"hidden_dim\"),\n","    \"dropout\":       best_hp.get(\"dropout\"),\n","    \"learning_rate\": best_hp.get(\"learning_rate\"),\n","}\n","with open(HP_PATH, \"w\") as f:\n","    json.dump(hp_dict, f, indent=4)\n","print(f\"[{WIN_KEY}] Best HPs saved → {HP_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsB-PjBl6Lwb","executionInfo":{"status":"ok","timestamp":1754937242662,"user_tz":-60,"elapsed":30,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"a2da9a02-4a24-4c35-d2d6-f708c3f3e227"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[48to12] Best HPs saved → /content/drive/MyDrive/EdgeMeter_AIv2/data/best_liteformer_hp_48to12.json\n"]}]},{"cell_type":"code","source":["# Log\n","best_model = tuner.get_best_models(1)[0]\n","platform_info = platform.platform()\n","tune_log = {\n","    \"window\": WIN_KEY,\n","    \"model\": \"LiteFormerV1\",\n","    \"task\": \"Smart Meter Energy Forecasting\",\n","    \"tuning_type\": \"BayesianOptimization\",\n","    \"subset_frac\": subset_frac,\n","    \"timesteps\": int(timesteps),\n","    \"n_features\": int(n_features),\n","    \"out_steps\": int(out_steps),\n","    \"tuning_time_minutes\": round((end_time - start_time) / 60, 2),\n","    \"best_hyperparameters\": hp_dict,\n","    \"total_params\": int(best_model.count_params()),\n","    \"input_shape\": list(X_train.shape[1:]),\n","    \"sequence_length\": int(X_train.shape[1]),\n","    \"gpu_used\": gpu_name,\n","    \"platform\": platform_info,\n","    \"log_type\": \"Tuning\"\n","}\n","with open(LOG_PATH, \"w\") as f:\n","    json.dump(tune_log, f, indent=4)\n","\n","print(f\"[{WIN_KEY}] Tuning log → {LOG_PATH}\")\n","print(\"LiteFormer v2 tuning (with v1 architecture) complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EiI_6DzgAlGO","executionInfo":{"status":"ok","timestamp":1754937246164,"user_tz":-60,"elapsed":2196,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"ac96c69b-2af1-4f66-85f2-322366213506"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[48to12] Tuning log → /content/drive/MyDrive/EdgeMeter_AIv2/data/liteformer_tuning_log_48to12.json\n","LiteFormer v2 tuning (with v1 architecture) complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}]}]}