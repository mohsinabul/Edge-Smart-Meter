{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMNNqLeXSMeimlkJUOqS2sG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip -q install -U keras-tuner gputil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFI8WqzdPaiH","executionInfo":{"status":"ok","timestamp":1754770184690,"user_tz":-60,"elapsed":4944,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"5ff4ab52-d816-4af6-ab2a-7799fb88e18e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import os, json, time, platform, zipfile\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import keras_tuner as kt\n","import GPUtil\n","from google.colab import files"],"metadata":{"id":"JISdZiq2PfLz","executionInfo":{"status":"ok","timestamp":1754770190766,"user_tz":-60,"elapsed":4227,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfKIQ2DnSlMQ","executionInfo":{"status":"ok","timestamp":1754770205983,"user_tz":-60,"elapsed":15208,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"4a4817bf-72fb-4c44-ac4b-22b231b9d782"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Point these folders to where each window's .npy live\n","WINDOW_DIRS = {\n","    \"48to12\": \"/content/drive/MyDrive/EdgeMeter_AIv2/data\",\n","    \"96to12\": \"/content/drive/MyDrive/EdgeMeter_AIv2/data\",\n","}\n","# Map window keys to filename suffixes\n","WINDOW_TAGS = {\n","    \"48to12\": \"48_12\",\n","    \"96to12\": \"96_12\",\n","}\n","\n","# Reproducibility\n","tf.random.set_seed(42)\n","np.random.seed(42)"],"metadata":{"id":"KqEAWLXSPh7p","executionInfo":{"status":"ok","timestamp":1754770205987,"user_tz":-60,"elapsed":2,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Loader that enforces the correct window tag\n","def _load_for_tag(d, base, tag):\n","    \"\"\"Load base.npy or base_<tag>.npy; prefer exact tag when present.\"\"\"\n","    p_tag = os.path.join(d, f\"{base}_{tag}.npy\")\n","    p_plain = os.path.join(d, f\"{base}.npy\")\n","    if os.path.exists(p_tag):\n","        return np.load(p_tag)\n","    if os.path.exists(p_plain):\n","        return np.load(p_plain)\n","    raise FileNotFoundError(f\"Missing {base}_{tag}.npy (or {base}.npy) in {d}\")\n","\n","def load_split_npys(d, tag):\n","    X_train = _load_for_tag(d, \"X_train\", tag)\n","    y_train = _load_for_tag(d, \"y_train\", tag)\n","    X_val   = _load_for_tag(d, \"X_val\",   tag)\n","    y_val   = _load_for_tag(d, \"y_val\",   tag)\n","    X_test  = _load_for_tag(d, \"X_test\",  tag)\n","    y_test  = _load_for_tag(d, \"y_test\",  tag)\n","\n","    # V2 shapes: X=(N,T,F), y=(N,12)\n","    assert X_train.ndim==3 and X_val.ndim==3 and X_test.ndim==3, \"X must be (N,T,F)\"\n","    assert y_train.ndim==2 and y_val.ndim==2 and y_test.ndim==2, \"y must be (N,12)\"\n","    assert y_train.shape[1]==12 and y_val.shape[1]==12 and y_test.shape[1]==12, \"y must have 12 steps\"\n","\n","    # Hard NaN checks\n","    for arr, name in [(X_train,\"X_train\"),(X_val,\"X_val\"),(X_test,\"X_test\"),\n","                      (y_train,\"y_train\"),(y_val,\"y_val\"),(y_test,\"y_test\")]:\n","        if np.isnan(arr).any():\n","            raise ValueError(f\"NaNs detected in {name}\")\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test\n"],"metadata":{"id":"UMtxaZ-Hcv6b","executionInfo":{"status":"ok","timestamp":1754770213264,"user_tz":-60,"elapsed":7,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Yf16Ws4PPTgS","executionInfo":{"status":"ok","timestamp":1754770215700,"user_tz":-60,"elapsed":10,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"outputs":[],"source":["# Model builder\n","def make_builder(timesteps, n_features, out_steps):\n","    def build_model(hp):\n","        units   = hp.Int('units', min_value=32, max_value=128, step=32)\n","        dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n","        lr      = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n","\n","        model = keras.Sequential([\n","            layers.Input(shape=(timesteps, n_features)),\n","            layers.LSTM(units),\n","            layers.Dropout(dropout),\n","            layers.Dense(out_steps)\n","        ])\n","        model.compile(\n","            optimizer=keras.optimizers.Adam(learning_rate=lr),\n","            loss='mse',\n","            metrics=['mae']\n","        )\n","        return model\n","    return build_model"]},{"cell_type":"code","source":["# GPU info\n","gpus = tf.config.list_physical_devices('GPU')\n","print(\"GPUs visible to TF:\", gpus)\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n","    except:\n","        pass\n","gpu_name = GPUtil.getGPUs()[0].name if GPUtil.getGPUs() else \"None\"\n","print(\"GPU in use:\", gpu_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBMy90r6a1Pr","executionInfo":{"status":"ok","timestamp":1754770219091,"user_tz":-60,"elapsed":33,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"0b6f81a5-b4e3-4955-bcfc-c8e11b67160f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["GPUs visible to TF: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","GPU in use: Tesla T4\n"]}]},{"cell_type":"code","source":["for win_key, DATA_DIR in WINDOW_DIRS.items():\n","    tag = WINDOW_TAGS[win_key]\n","    print(f\"\\n Tuning window: {win_key} (tag {tag}) | dir: {DATA_DIR} \")\n","    LOG_PATH = os.path.join(DATA_DIR, f\"lstm_tuning_log_{win_key}.json\")\n","    HP_PATH  = os.path.join(DATA_DIR, f\"best_lstm_hp_{win_key}.json\")\n","\n","    # Load correct files for this window\n","    X_train, y_train, X_val, y_val, X_test, y_test = load_split_npys(DATA_DIR, tag)\n","    print(f\"Train X: {X_train.shape} | y: {y_train.shape}\")\n","    print(f\"Val   X: {X_val.shape}   | y: {y_val.shape}\")\n","    print(f\"Test  X: {X_test.shape}  | y: {y_test.shape}\")\n","\n","    # sanity: enforce expected timesteps per window\n","    expected_T = 48 if win_key == \"48to12\" else 96\n","    assert X_train.shape[1] == expected_T, f\"Loaded wrong window: expected T={expected_T}, got {X_train.shape[1]}\"\n","\n","    timesteps  = X_train.shape[1]\n","    n_features = X_train.shape[2]\n","    out_steps  = y_train.shape[1]\n","\n","    # 5% subset (same as V1)\n","    subset_frac = 0.05\n","    X_train_small = X_train[:int(subset_frac * X_train.shape[0])]\n","    y_train_small = y_train[:int(subset_frac * y_train.shape[0])]\n","    X_val_small   = X_val[:int(subset_frac * X_val.shape[0])]\n","    y_val_small   = y_val[:int(subset_frac * y_val.shape[0])]\n","    print(f\"Subset shapes: {X_train_small.shape} | {X_val_small.shape}\")\n","\n","    # Builder + Tuner\n","    builder = make_builder(timesteps, n_features, out_steps)\n","    tuner = kt.BayesianOptimization(\n","        builder,\n","        objective='val_loss',\n","        max_trials=20,\n","        directory=DATA_DIR,\n","        project_name=f'lstm_retune_{win_key}'   # unique per window\n","    )\n","\n","    early_stop = keras.callbacks.EarlyStopping(\n","        monitor='val_loss',\n","        patience=4,\n","        restore_best_weights=True\n","    )\n","\n","    # Search\n","    start_time = time.time()\n","    with tf.device('/GPU:0'):\n","        tuner.search(\n","            X_train_small, y_train_small,\n","            validation_data=(X_val_small, y_val_small),\n","            epochs=50,\n","            batch_size=512,\n","            callbacks=[early_stop],\n","            verbose=1\n","        )\n","    end_time = time.time()\n","\n","    # Saving best HPs\n","    best_hp = tuner.get_best_hyperparameters(1)[0]\n","    hp_dict = {\n","        'units': best_hp.get('units'),\n","        'dropout': best_hp.get('dropout'),\n","        'learning_rate': best_hp.get('learning_rate')\n","    }\n","    with open(HP_PATH, 'w') as f:\n","        json.dump(hp_dict, f, indent=4)\n","\n","    # Log\n","    model_tmp = builder(best_hp)\n","    total_params = model_tmp.count_params()\n","    platform_info = platform.platform()\n","\n","    log = {\n","        \"window\": win_key,\n","        \"model\": \"LSTM\",\n","        \"task\": \"Smart Meter Energy Forecasting\",\n","        \"tuning_type\": \"BayesianOptimization\",\n","        \"tuning_time_minutes\": round((end_time - start_time) / 60, 2),\n","        \"best_hyperparameters\": hp_dict,\n","        \"total_params\": int(total_params),\n","        \"input_shape\": list(X_train.shape[1:]),\n","        \"sequence_length\": int(X_train.shape[1]),\n","        \"gpu_used\": gpu_name,\n","        \"platform\": platform_info,\n","        \"log_type\": \"Tuning\"\n","    }\n","    with open(LOG_PATH, 'w') as f:\n","        json.dump(log, f, indent=4)\n","\n","    print(f\"[{win_key}] Best HPs saved → {HP_PATH}\")\n","    print(f\"[{win_key}] Tuning log  → {LOG_PATH}\")\n","\n","print(\"\\nAll tuning runs completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"bMVJEPIhUBAO","executionInfo":{"status":"error","timestamp":1754775568550,"user_tz":-60,"elapsed":67,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"24c58cc0-5e74-44d6-bd0c-6cf87c79ec97"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'WINDOW_DIRS' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4209572990.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mwin_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWINDOW_DIRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWINDOW_TAGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwin_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Tuning window: {win_key} (tag {tag}) | dir: {DATA_DIR} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mLOG_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"lstm_tuning_log_{win_key}.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mHP_PATH\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"best_lstm_hp_{win_key}.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'WINDOW_DIRS' is not defined"]}]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","# LSTM Hyperparameter Tuning — 96→12 only (Colab + Google Drive)\n","# Same model/tuner as V1; 5% subset; per-window logs; memmap I/O to avoid RAM spikes.\n","\n","!pip -q install -U keras-tuner gputil\n","\n","import os, json, time, platform\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import keras_tuner as kt\n","import GPUtil\n","from google.colab import drive\n","\n","# ---- Mount Drive ----\n","drive.mount('/content/drive', force_remount=True)\n","\n","# ---- Point to your .npy folder (same folder is fine for both windows) ----\n","DATA_DIR = \"/content/drive/MyDrive/EdgeMeter_AIv2/data\"  # <-- change if yours differs\n","WIN_KEY  = \"96to12\"\n","WIN_TAG  = \"96_12\"\n","\n","HP_PATH  = os.path.join(DATA_DIR, f\"best_lstm_hp_{WIN_KEY}.json\")\n","LOG_PATH = os.path.join(DATA_DIR, f\"lstm_tuning_log_{WIN_KEY}.json\")\n","\n","# ---- Reproducibility ----\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","# ---- GPU info (unchanged) ----\n","gpus = tf.config.list_physical_devices('GPU')\n","print(\"GPUs visible to TF:\", gpus)\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","    except Exception:\n","        pass\n","gpu_name = GPUtil.getGPUs()[0].name if GPUtil.getGPUs() else \"None\"\n","print(\"GPU in use:\", gpu_name)\n","\n","# ---- Safe loader: memory-mapped + window tag + NaN scan ----\n","def _pick_path(d, base, tag):\n","    p_tag = os.path.join(d, f\"{base}_{tag}.npy\")\n","    p_plain = os.path.join(d, f\"{base}.npy\")\n","    if os.path.exists(p_tag):   return p_tag\n","    if os.path.exists(p_plain): return p_plain\n","    raise FileNotFoundError(f\"Missing {base}_{tag}.npy (or {base}.npy) in {d}\")\n","\n","def _nan_scan(mm, step=8192):\n","    n = mm.shape[0]\n","    for i in range(0, n, step):\n","        if np.isnan(mm[i:i+step]).any():\n","            raise ValueError(\"NaNs detected in array.\")\n","\n","def load_split_npys_memmap(d, tag):\n","    X_train = np.load(_pick_path(d,\"X_train\",tag), mmap_mode=\"r\")\n","    y_train = np.load(_pick_path(d,\"y_train\",tag), mmap_mode=\"r\")\n","    X_val   = np.load(_pick_path(d,\"X_val\",  tag), mmap_mode=\"r\")\n","    y_val   = np.load(_pick_path(d,\"y_val\",  tag), mmap_mode=\"r\")\n","    X_test  = np.load(_pick_path(d,\"X_test\", tag), mmap_mode=\"r\")\n","    y_test  = np.load(_pick_path(d,\"y_test\", tag), mmap_mode=\"r\")\n","\n","    # Shape checks\n","    assert X_train.ndim==3 and X_val.ndim==3 and X_test.ndim==3, \"X must be (N,T,F)\"\n","    assert y_train.ndim==2 and y_val.ndim==2 and y_test.ndim==2, \"y must be (N,12)\"\n","    assert y_train.shape[1]==12 and y_val.shape[1]==12 and y_test.shape[1]==12, \"y must have 12 steps\"\n","\n","    # Chunked NaN scans\n","    for arr in (X_train, X_val, X_test, y_train, y_val, y_test):\n","        _nan_scan(arr)\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test\n","\n","# ---- Load 96→12 ----\n","X_train, y_train, X_val, y_val, X_test, y_test = load_split_npys_memmap(DATA_DIR, WIN_TAG)\n","print(f\"Train X: {X_train.shape} | y: {y_train.shape}\")\n","print(f\"Val   X: {X_val.shape}   | y: {y_val.shape}\")\n","print(f\"Test  X: {X_test.shape}  | y: {y_test.shape}\")\n","assert X_train.shape[1] == 96, f\"Expected T=96; got {X_train.shape[1]}\"\n","\n","timesteps  = X_train.shape[1]\n","n_features = X_train.shape[2]\n","out_steps  = y_train.shape[1]\n","\n","# ---- 5% subset (materialize only the needed rows into RAM) ----\n","subset_frac = 0.05\n","n_train_sub = max(1, int(subset_frac * X_train.shape[0]))\n","n_val_sub   = max(1, int(subset_frac * X_val.shape[0]))\n","\n","X_train_small = np.asarray(X_train[:n_train_sub])\n","y_train_small = np.asarray(y_train[:n_train_sub])\n","X_val_small   = np.asarray(X_val[:n_val_sub])\n","y_val_small   = np.asarray(y_val[:n_val_sub])\n","\n","print(f\"Subsets -> X_train_small {X_train_small.shape} | X_val_small {X_val_small.shape}\")\n","\n","# ---- Model builder (same as V1) ----\n","def make_builder(timesteps, n_features, out_steps):\n","    def build_model(hp):\n","        units   = hp.Int('units', min_value=32, max_value=128, step=32)\n","        dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n","        lr      = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n","\n","        model = keras.Sequential([\n","            layers.Input(shape=(timesteps, n_features)),\n","            layers.LSTM(units),\n","            layers.Dropout(dropout),\n","            layers.Dense(out_steps)\n","        ])\n","        model.compile(\n","            optimizer=keras.optimizers.Adam(learning_rate=lr),\n","            loss='mse',\n","            metrics=['mae']\n","        )\n","        return model\n","    return build_model\n","\n","builder = make_builder(timesteps, n_features, out_steps)\n","\n","# ---- Tuner (same as V1) ----\n","tuner = kt.BayesianOptimization(\n","    builder,\n","    objective='val_loss',\n","    max_trials=20,\n","    directory=DATA_DIR,                    # keep artifacts next to data\n","    project_name=f'lstm_retune_{WIN_KEY}'  # unique per window\n",")\n","\n","early_stop = keras.callbacks.EarlyStopping(\n","    monitor='val_loss', patience=4, restore_best_weights=True\n",")\n","\n","# Slightly smaller batch for 96→12 to avoid GPU OOM (still comparable)\n","batch_size = 256  # use 512 if your GPU has headroom\n","\n","# ---- Search ----\n","device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n","print(\"Using device:\", device)\n","\n","start_time = time.time()\n","with tf.device(device):\n","    tuner.search(\n","        X_train_small, y_train_small,\n","        validation_data=(X_val_small, y_val_small),\n","        epochs=50,\n","        batch_size=batch_size,\n","        callbacks=[early_stop],\n","        verbose=1\n","    )\n","end_time = time.time()\n","\n","# ---- Save best HPs ----\n","best_hp = tuner.get_best_hyperparameters(1)[0]\n","hp_dict = {\n","    'units': best_hp.get('units'),\n","    'dropout': best_hp.get('dropout'),\n","    'learning_rate': best_hp.get('learning_rate')\n","}\n","with open(HP_PATH, 'w') as f:\n","    json.dump(hp_dict, f, indent=4)\n","\n","# ---- Log (V1-style fields) ----\n","tmp_model = builder(best_hp)\n","total_params = tmp_model.count_params()\n","platform_info = platform.platform()\n","\n","tune_log = {\n","    \"window\": WIN_KEY,\n","    \"model\": \"LSTM\",\n","    \"task\": \"Smart Meter Energy Forecasting\",\n","    \"tuning_type\": \"BayesianOptimization\",\n","    \"subset_frac\": subset_frac,\n","    \"timesteps\": int(timesteps),\n","    \"n_features\": int(n_features),\n","    \"out_steps\": int(out_steps),\n","    \"tuning_time_minutes\": round((end_time - start_time) / 60, 2),\n","    \"best_hyperparameters\": hp_dict,\n","    \"total_params\": int(total_params),\n","    \"gpu_used\": gpu_name,\n","    \"platform\": platform_info,\n","    \"log_type\": \"Tuning\"\n","}\n","with open(LOG_PATH, 'w') as f:\n","    json.dump(tune_log, f, indent=4)\n","\n","print(f\"\\n[{WIN_KEY}] Best HPs saved → {HP_PATH}\")\n","print(f\"[{WIN_KEY}] Tuning log  → {LOG_PATH}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zlzi2KyxdaKZ","executionInfo":{"status":"ok","timestamp":1754783262312,"user_tz":-60,"elapsed":7642501,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"87f38b9c-c3fc-427a-8fd1-2f9cf1e91822"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 20 Complete [00h 06m 46s]\n","val_loss: 0.09350237995386124\n","\n","Best val_loss So Far: 0.09350237995386124\n","Total elapsed time: 01h 54m 57s\n","\n","[96to12] Best HPs saved → /content/drive/MyDrive/EdgeMeter_AIv2/data/best_lstm_hp_96to12.json\n","[96to12] Tuning log  → /content/drive/MyDrive/EdgeMeter_AIv2/data/lstm_tuning_log_96to12.json\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import os\n","import time\n","\n","# Delay a bit to ensure all file writes are complete\n","print(\"✅ All code executed. Disconnecting runtime in 5 seconds...\")\n","time.sleep(60)\n","\n","# Disconnect runtime\n","os.kill(os.getpid(), 9)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_s6SXnq1hqT","outputId":"400ac6a3-93ab-4106-9bad-8075924dc145"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ All code executed. Disconnecting runtime in 5 seconds...\n"]}]}]}