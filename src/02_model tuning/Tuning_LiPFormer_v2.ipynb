{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOEfkfFMteW5KAFidk43I3v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpUNW8_wT-fT","executionInfo":{"status":"ok","timestamp":1754919159449,"user_tz":-60,"elapsed":8779,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"30b673c3-df71-40ee-daea-bc0ba3459d96"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip -q install -U keras-tuner gputil\n"]},{"cell_type":"code","source":["import os, json, time, platform, zipfile\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import keras_tuner as kt\n","import GPUtil\n","from google.colab import files\n","from google.colab import drive"],"metadata":{"id":"tBtP3wotWGoR","executionInfo":{"status":"ok","timestamp":1754919368106,"user_tz":-60,"elapsed":5,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Colab: Mount Drive \\\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8qnT2ioUNnZ","executionInfo":{"status":"ok","timestamp":1754919204427,"user_tz":-60,"elapsed":44974,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"ed597d7c-053f-4f2a-cdd8-a7e21c937347"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Paths\n","DATA_DIR = \"/content/drive/MyDrive/EdgeMeter_AIv2/data\"\n","WIN_KEY  = \"48to12\"\n","WIN_TAG  = \"48_12\"\n","\n","HP_PATH  = os.path.join(DATA_DIR, f\"best_lipformer_hp_{WIN_KEY}.json\")\n","LOG_PATH = os.path.join(DATA_DIR, f\"lipformer_tuning_log_{WIN_KEY}.json\")\n","\n","# Reproducibility\n","tf.random.set_seed(42)\n","np.random.seed(42)\n"],"metadata":{"id":"WpGUva-rUONK","executionInfo":{"status":"ok","timestamp":1754919422653,"user_tz":-60,"elapsed":7,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# GPU info\n","gpus = tf.config.list_physical_devices('GPU')\n","print(\"GPUs visible to TF:\", gpus)\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","    except Exception:\n","        pass\n","gpu_name = GPUtil.getGPUs()[0].name if GPUtil.getGPUs() else \"None\"\n","print(\"GPU in use:\", gpu_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4OAE4Q1UQK_","executionInfo":{"status":"ok","timestamp":1754919426162,"user_tz":-60,"elapsed":49,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"3f6e4477-45a0-41db-a3b0-f899e93849c6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["GPUs visible to TF: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","GPU in use: NVIDIA A100-SXM4-40GB\n"]}]},{"cell_type":"code","source":["# Loading Data (48→12)\n","def _path(d, base, tag):\n","    p1 = os.path.join(d, f\"{base}_{tag}.npy\")\n","    p0 = os.path.join(d, f\"{base}.npy\")\n","    if os.path.exists(p1): return p1\n","    if os.path.exists(p0): return p0\n","    raise FileNotFoundError(f\"Missing {base}_{tag}.npy (or {base}.npy) in {d}\")\n","\n","X_train = np.load(_path(DATA_DIR, \"X_train\", WIN_TAG))\n","y_train = np.load(_path(DATA_DIR, \"y_train\", WIN_TAG))\n","X_val   = np.load(_path(DATA_DIR, \"X_val\",   WIN_TAG))\n","y_val   = np.load(_path(DATA_DIR, \"y_val\",   WIN_TAG))\n","X_test  = np.load(_path(DATA_DIR, \"X_test\",  WIN_TAG))\n","y_test  = np.load(_path(DATA_DIR, \"y_test\",  WIN_TAG))\n","\n","# Shape checks\n","assert X_train.ndim==3 and X_val.ndim==3 and X_test.ndim==3, \"X must be (N,T,F)\"\n","assert y_train.ndim==2 and y_val.ndim==2 and y_test.ndim==2, \"y must be (N,12)\"\n","assert y_train.shape[1]==12 and y_val.shape[1]==12 and y_test.shape[1]==12, \"y must have 12 steps\"\n","assert X_train.shape[1]==48, f\"Expected T=48; got {X_train.shape[1]}\"\n","\n","for name, arr in [(\"X_train\",X_train), (\"X_val\",X_val), (\"X_test\",X_test),\n","                  (\"y_train\",y_train), (\"y_val\",y_val), (\"y_test\",y_test)]:\n","    if np.isnan(arr).any():\n","        raise ValueError(f\"NaNs detected in {name}\")\n","\n","timesteps  = X_train.shape[1]  # 48\n","n_features = X_train.shape[2]\n","out_steps  = y_train.shape[1]  # 12\n","\n","print(f\"Train X: {X_train.shape} | y: {y_train.shape}\")\n","print(f\"Val   X: {X_val.shape}   | y: {y_val.shape}\")\n","print(f\"Test  X: {X_test.shape}  | y: {y_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7qxZZt4UVpl","executionInfo":{"status":"ok","timestamp":1754919907996,"user_tz":-60,"elapsed":480210,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"049e7ac3-b5e4-40a3-f8b1-0248b4d307cb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train X: (10719826, 48, 11) | y: (10719826, 12)\n","Val   X: (3072784, 48, 11)   | y: (3072784, 12)\n","Test  X: (1536392, 48, 11)  | y: (1536392, 12)\n"]}]},{"cell_type":"code","source":["# 5% subset\n","subset_frac   = 0.05\n","n_train_small = max(1, int(subset_frac * X_train.shape[0]))\n","n_val_small   = max(1, int(subset_frac * X_val.shape[0]))\n","\n","X_train_small = X_train[:n_train_small]\n","y_train_small = y_train[:n_train_small]\n","X_val_small   = X_val[:n_val_small]\n","y_val_small   = y_val[:n_val_small]\n","\n","print(f\"Subset shapes -> X_train_small: {X_train_small.shape} | X_val_small: {X_val_small.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ni7nGaLUX73","executionInfo":{"status":"ok","timestamp":1754919908009,"user_tz":-60,"elapsed":24,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"8b8e30f3-ed19-477f-db87-8bfa8a00bf16"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Subset shapes -> X_train_small: (535991, 48, 11) | X_val_small: (153639, 48, 11)\n"]}]},{"cell_type":"code","source":["# LiPFormer V2\n","def patchify(x, patch_size):\n","    # (B, T, F) -> (B, P, patch_size*F), P = floor(T/patch_size)\n","    T = tf.shape(x)[1]\n","    F = tf.shape(x)[2]\n","    t_trim = (T // patch_size) * patch_size\n","    x = x[:, :t_trim, :]\n","    P = t_trim // patch_size\n","    return tf.reshape(x, [tf.shape(x)[0], P, patch_size * F])\n","\n","def lipformer_block(x, hp):\n","    \"\"\"V1 LiPFormer idea + V2 upgrades:\n","       - Project to embed_dim\n","       - PreNorm -> Attention (choose MHA 2–4 heads OR lightweight 'linear' path)\n","       - Residual\n","       - PreNorm -> FFN (bigger ff_dim) + dropout\n","       - Residual\n","    \"\"\"\n","    # search space\n","    patch_embed  = hp.Choice(\"embed_dim\", values=[64, 96, 128])\n","    use_mha      = hp.Boolean(\"use_mha\", default=True)\n","    num_heads    = hp.Int(\"num_heads\", 2, 4, step=1)          # only used if use_mha=True\n","    key_dim      = hp.Int(\"key_dim\",   16, 64, step=16)       # only used if use_mha=True\n","    attn_dropout = hp.Choice(\"attn_dropout\", values=[0.0, 0.1, 0.2])\n","    ff_dim       = hp.Choice(\"ff_dim\", values=[64, 128, 192, 256])  # ↑ vs V1\n","    ff_dropout   = hp.Choice(\"ff_dropout\", values=[0.0, 0.1, 0.2])\n","\n","    # Project patches to a stable embed size\n","    x = layers.Dense(patch_embed)(x)\n","\n","    # Attention block\n","    y = layers.LayerNormalization(epsilon=1e-6)(x)\n","    if use_mha:\n","        # Multi-Head Attention (2–4 heads)\n","        y = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=key_dim, dropout=attn_dropout\n","        )(y, y)\n","    else:\n","        # Lightweight \"linear\" attention path\n","        q = layers.Dense(patch_embed)(y)\n","        k = layers.Dense(patch_embed)(y)\n","        v = layers.Dense(patch_embed)(y)\n","        scale = tf.math.sqrt(tf.cast(patch_embed, tf.float32))\n","        attn = tf.nn.softmax(tf.matmul(q, k, transpose_b=True) / scale, axis=-1)\n","        y = tf.matmul(attn, v)\n","        if attn_dropout > 0.0:\n","            y = layers.Dropout(attn_dropout)(y)\n","    x = layers.Add()([x, y])  # residual\n","\n","    # FFN block\n","    y = layers.LayerNormalization(epsilon=1e-6)(x)\n","    y = layers.Dense(ff_dim, activation=\"gelu\")(y)\n","    if ff_dropout > 0.0:\n","        y = layers.Dropout(ff_dropout)(y)\n","    y = layers.Dense(patch_embed)(y)\n","    x = layers.Add()([x, y])  # residual\n","    return x\n","\n","def make_builder(timesteps, n_features, out_steps):\n","    def build_model(hp):\n","        patch_size = hp.Choice(\"patch_size\", values=[4, 6, 8, 12])\n","\n","        inputs = keras.Input(shape=(timesteps, n_features))\n","        x = layers.Lambda(lambda t: patchify(t, patch_size))(inputs)  # (B,P,patch_size*F)\n","        x = lipformer_block(x, hp)\n","\n","        x = layers.GlobalAveragePooling1D()(x)\n","        outputs = layers.Dense(out_steps)(x)\n","\n","        model = keras.Model(inputs, outputs)\n","        lr = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n","        model.compile(\n","            optimizer=keras.optimizers.Adam(learning_rate=lr),\n","            loss=\"mse\",\n","            metrics=[\"mae\"]\n","        )\n","        return model\n","    return build_model\n","\n","builder = make_builder(timesteps, n_features, out_steps)\n"],"metadata":{"id":"-ouHN-RDUfgm","executionInfo":{"status":"ok","timestamp":1754919908031,"user_tz":-60,"elapsed":23,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Tuner\n","tuner = kt.BayesianOptimization(\n","    builder,\n","    objective=\"val_loss\",\n","    max_trials=20,\n","    directory=DATA_DIR,\n","    project_name=f\"lipformer_retune_{WIN_KEY}\"\n",")\n","\n","early_stop = keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\", patience=4, restore_best_weights=True\n",")\n","\n","device = \"/GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"\n","print(\"Using device:\", device)\n","\n","start_time = time.time()\n","with tf.device(device):\n","    tuner.search(\n","        X_train_small, y_train_small,\n","        validation_data=(X_val_small, y_val_small),\n","        epochs=50,\n","        batch_size=512,\n","        callbacks=[early_stop],\n","        verbose=1\n","    )\n","end_time = time.time()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i46B5PuxUiL2","executionInfo":{"status":"ok","timestamp":1754922165854,"user_tz":-60,"elapsed":2257814,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"c94f542c-b332-4050-c92e-35098020a25a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 20 Complete [00h 00m 01s]\n","\n","Best val_loss So Far: 0.088422492146492\n","Total elapsed time: 00h 37m 36s\n"]}]},{"cell_type":"code","source":["# Saving best HPs\n","best_hp = tuner.get_best_hyperparameters(1)[0]\n","hp_dict = {\n","    \"patch_size\":     best_hp.get(\"patch_size\"),\n","    \"embed_dim\":      best_hp.get(\"embed_dim\"),\n","    \"use_mha\":        best_hp.get(\"use_mha\"),\n","    \"num_heads\":      best_hp.get(\"num_heads\") if best_hp.get(\"use_mha\") else None,\n","    \"key_dim\":        best_hp.get(\"key_dim\")   if best_hp.get(\"use_mha\") else None,\n","    \"attn_dropout\":   best_hp.get(\"attn_dropout\"),\n","    \"ff_dim\":         best_hp.get(\"ff_dim\"),\n","    \"ff_dropout\":     best_hp.get(\"ff_dropout\"),\n","    \"learning_rate\":  best_hp.get(\"learning_rate\"),\n","}\n","with open(HP_PATH, \"w\") as f:\n","    json.dump(hp_dict, f, indent=4)\n","print(f\"[{WIN_KEY}] Best HPs saved → {HP_PATH}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6aUvmqlUkb_","executionInfo":{"status":"ok","timestamp":1754922165879,"user_tz":-60,"elapsed":12,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"b067b7a0-d0af-437f-d2d3-ae5bfd637f07"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[48to12] Best HPs saved → /content/drive/MyDrive/EdgeMeter_AIv2/data/best_lipformer_hp_48to12.json\n"]}]},{"cell_type":"code","source":["# Log\n","tmp_model = tuner.get_best_models(1)[0]\n","platform_info = platform.platform()\n","\n","tune_log = {\n","    \"window\": WIN_KEY,\n","    \"model\": \"LiPFormerV2\",\n","    \"task\": \"Smart Meter Energy Forecasting\",\n","    \"tuning_type\": \"BayesianOptimization\",\n","    \"subset_frac\": subset_frac,\n","    \"timesteps\": int(timesteps),\n","    \"n_features\": int(n_features),\n","    \"out_steps\": int(out_steps),\n","    \"tuning_time_minutes\": round((end_time - start_time) / 60, 2),\n","    \"best_hyperparameters\": hp_dict,\n","    \"total_params\": int(tmp_model.count_params()),\n","    \"input_shape\": list(X_train.shape[1:]),\n","    \"sequence_length\": int(X_train.shape[1]),\n","    \"gpu_used\": gpu_name,\n","    \"platform\": platform_info,\n","    \"log_type\": \"Tuning\"\n","}\n","with open(LOG_PATH, \"w\") as f:\n","    json.dump(tune_log, f, indent=4)\n","\n","print(f\"[{WIN_KEY}] Tuning log  → {LOG_PATH}\")\n","print(\"LiPFormer V2 48→12 tuning complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHf8uUJlUmzk","executionInfo":{"status":"ok","timestamp":1754922170806,"user_tz":-60,"elapsed":4529,"user":{"displayName":"Abul Mohsin","userId":"04862932652821291928"}},"outputId":"0d47a117-7e3e-42f5-9aea-5084849c14f8"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[48to12] Tuning log  → /content/drive/MyDrive/EdgeMeter_AIv2/data/lipformer_tuning_log_48to12.json\n","LiPFormer V2 48→12 tuning complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}]}]}